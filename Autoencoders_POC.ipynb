{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders_POC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhranil-datascience/SOM_And_AutoEncodersPOC/blob/master/Autoencoders_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec_bewtLu6oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################## Mount Drive ######################################## \n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "############################## Change Directory ###################################\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/MLandDLFullCourse/DL/Autoencoders')\n",
        "########## Suppress Warnings ############\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "########## Import Dataset ############\n",
        "import pandas as pd\n",
        "TrainingSet=pd.read_csv(filepath_or_buffer='u1.base',header=None,delimiter='\\t')\n",
        "TrainingSet=TrainingSet.iloc[:,0:3].values\n",
        "TestSet=pd.read_csv(filepath_or_buffer='u1.test',header=None,delimiter='\\t')\n",
        "TestSet=TestSet.iloc[:,0:3].values\n",
        "######### Check Max Movie number and Customer Number ################\n",
        "### Customer ###\n",
        "MaxCusNum=max(max(TrainingSet[:,0]),max(TestSet[:,0]))\n",
        "### Movie ###\n",
        "MaxMovNum=max(max(TrainingSet[:,1]),max(TestSet[:,1]))\n",
        "######## Create Dataset ##############\n",
        "def CreateDataset(Set):\n",
        "  MovieAndRating=[]\n",
        "  for count in range(0,MaxCusNum):\n",
        "    Rating=Set[:,1:3][Set[:,0]==count+1]\n",
        "    UserRatings=[0]*MaxMovNum\n",
        "    for i in range(0,MaxMovNum):\n",
        "      if i+1 in Rating[:,0]:\n",
        "        tempvar=Rating[:,1][Rating[:,0]==i+1]\n",
        "        UserRatings[i]=UserRatings[i]+tempvar[0]\n",
        "    MovieAndRating.append(UserRatings)\n",
        "  return MovieAndRating\n",
        "import numpy as np\n",
        "MovieAndRatingTrain=np.array(CreateDataset(TrainingSet))\n",
        "MovieAndRatingTest=np.array(CreateDataset(TestSet))\n",
        "MovieAndRatingTrainAutoencoder=np.expand_dims(MovieAndRatingTrain,axis=0)\n",
        "MovieAndRatingTestAutoencoder=np.expand_dims(MovieAndRatingTest,axis=0)\n",
        "############ Implement Autoencoder ####################\n",
        "from keras.layers import Dense,Input\n",
        "from keras.models import Model\n",
        "input_data=Input(shape=(MovieAndRatingTest.shape[0],MovieAndRatingTest.shape[1]))\n",
        "############################# Encoder #####################################\n",
        "##### Input Layer #######\n",
        "encoded=Dense(units=840,activation='relu')(input_data)\n",
        "##### Layer-1 #######\n",
        "encoded=Dense(units=420,activation='relu')(encoded)\n",
        "##### Layer-2 #######\n",
        "encoded=Dense(units=210,activation='relu')(encoded)\n",
        "##### Layer-3 #######\n",
        "encoded=Dense(units=105,activation='relu')(encoded)\n",
        "############################# Decoder #####################################\n",
        "##### Layer-1 #######\n",
        "decoded=Dense(units=105,activation='relu')(encoded)\n",
        "##### Layer-2 #######\n",
        "decoded=Dense(units=210,activation='relu')(decoded)\n",
        "##### Layer-3 #######\n",
        "decoded=Dense(units=420,activation='relu')(decoded)\n",
        "##### Layer-4 #######\n",
        "decoded=Dense(units=420,activation='relu')(decoded)\n",
        "###### Output Layer ##############\n",
        "decoded=Dense(units=MovieAndRatingTest.shape[1])(decoded)\n",
        "#### Create Model #########\n",
        "autoencoder=Model(input_data,decoded)\n",
        "autoencoder.compile(optimizer='adam',loss='mean_squared_error',metrics=['mae'])\n",
        "#### Train Autoencoder ######\n",
        "autoencoder.fit(x=MovieAndRatingTrainAutoencoder,y=MovieAndRatingTrainAutoencoder,batch_size=8,epochs=1500)\n",
        "Prediction=autoencoder.predict(MovieAndRatingTestAutoencoder)\n",
        "Prediction=Prediction[0,:,:]\n",
        "pred=Prediction.astype(int)\n",
        "original=MovieAndRatingTest.astype(int)\n",
        "np.savetxt(fname=\"OriginalTestSet.csv\",delimiter='\\t',X=original,fmt='%d')\n",
        "np.savetxt(fname=\"PredictedTestSet.csv\",delimiter='\\t',X=pred,fmt='%d')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}